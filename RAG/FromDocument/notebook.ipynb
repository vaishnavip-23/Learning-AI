{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407e2cf0",
   "metadata": {},
   "source": [
    "Here's the diagram for the process : [rag_image](mermaid_rag.png)\n",
    "Link to the Streamlit application : [rag_application](https://alice-in-wonderland-rag.streamlit.app/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9911ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Install dependencies\n",
    "\n",
    "%pip install langchain langchain-community langchain-huggingface langchain-google-genai --quiet\n",
    "%pip install chromadb sentence-transformers FlagEmbedding huggingface_hub --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7225c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Imports\n",
    "import os, re, json\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain components\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Reranker\n",
    "from FlagEmbedding import FlagReranker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8600151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Authentication (Hugging Face + Gemini key)\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Hugging Face login\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(HF_TOKEN)\n",
    "\n",
    "# Gemini API key\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "assert GOOGLE_API_KEY, \"Gemini API Key not found!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a4e1f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Summarizing chunks with OpenRouter gpt-oss-20b (token-aware splitting)...\n",
      "### Example 3 Chunks ###\n",
      "{\n",
      "  \"content\": \"**_ START OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND _**\\n\\nContents\\n\\nCHAPTER I. Down the Rabbit-Hole\\nCHAPTER II. The Pool of Tears\\nCHAPTER III. A Caucus-Race and a Long Tale\\nCHAPTER IV. The Rabbit Sends in a Little Bill\\nCHAPTER V. Advice from a Caterpillar\\nCHAPTER VI. Pig and Pepper\\nCHAPTER VII. A Mad Tea-Party\\nCHAPTER VIII. The Queen\\u2019s Croquet-Ground\\nCHAPTER IX. The Mock Turtle\\u2019s Story\\nCHAPTER X. The Lobster Quadrille\\nCHAPTER XI. Who Stole the Tarts?\\nCHAPTER XII. Alice\\u2019s Evidence\\n\\nCHAPTER I.\\nDown the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into\\nthe book her sister was reading, but it had no pictures or\\nconversations in it, \\u201cand what is the use of a book,\\u201d thought Alice\\n\\u201cwithout pictures or conversations?\\u201d\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure of\\nmaking a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\\n\\nThere was nothing so _very_ remarkable in that; nor did Alice think it\\nso _very_ much out of the way to hear the Rabbit say to itself, \\u201cOh\\ndear! Oh dear! I shall be late!\\u201d (when she thought it over afterwards,\\nit occurred to her that she ought to have wondered at this, but at the\\ntime it all seemed quite natural); but when the Rabbit actually _took a\\nwatch out of its waistcoat-pocket_, and looked at it, and then hurried\\non, Alice started to her feet, for it flashed across her mind that she\\nhad never before seen a rabbit with either a waistcoat-pocket, or a\\nwatch to take out of it, and burning with curiosity, she ran across the\\nfield after it, and fortunately was just in time to see it pop down a\\nlarge rabbit-hole under the hedge.\\n\\nIn another moment down went Alice after it, never once considering how\\nin the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then\\ndipped suddenly down, so suddenly that Alice had not a moment to think\\nabout stopping herself before she found herself falling down a very\\ndeep well.\",\n",
      "  \"metadata\": {\n",
      "    \"source\": \"alice_in_wonderland.md\",\n",
      "    \"chapter_number\": null,\n",
      "    \"chapter_title\": null,\n",
      "    \"start_index\": 1,\n",
      "    \"chunk_number\": 0,\n",
      "    \"chunk_summary\": \"Alice, bored while sitting beside her sister, remarks that \\u201cwithout pictures or conversations\\u201d a book is useless and contemplates making a daisy\\u2011chain, only to be interrupted by a White Rabbit who exclaims, \\u201cOh dear! Oh dear! I shall be late!\\u201d and pulls a watch from its waistcoat\\u2011pocket. Intrigued, she chases the rabbit down a large rabbit\\u2011hole, and, without a second thought, falls into a deep well, beginning her fantastical adventure. The passage captures her initial curiosity and the moment she steps into the unknown, setting the stage for the whimsical journey that follows.\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"content\": \"In another moment down went Alice after it, never once considering how\\nin the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then\\ndipped suddenly down, so suddenly that Alice had not a moment to think\\nabout stopping herself before she found herself falling down a very\\ndeep well.\\n\\nEither the well was very deep, or she fell very slowly, for she had\\nplenty of time as she went down to look about her and to wonder what\\nwas going to happen next. First, she tried to look down and make out\\nwhat she was coming to, but it was too dark to see anything; then she\\nlooked at the sides of the well, and noticed that they were filled with\\ncupboards and book-shelves; here and there she saw maps and pictures\\nhung upon pegs. She took down a jar from one of the shelves as she\\npassed; it was labelled \\u201cORANGE MARMALADE\\u201d, but to her great\\ndisappointment it was empty: she did not like to drop the jar for fear\\nof killing somebody underneath, so managed to put it into one of the\\ncupboards as she fell past it.\\n\\n\\u201cWell!\\u201d thought Alice to herself, \\u201cafter such a fall as this, I shall\\nthink nothing of tumbling down stairs! How brave they\\u2019ll all think me\\nat home! Why, I wouldn\\u2019t say anything about it, even if I fell off the\\ntop of the house!\\u201d (Which was very likely true.)\\n\\nDown, down, down. Would the fall _never_ come to an end? \\u201cI wonder how\\nmany miles I\\u2019ve fallen by this time?\\u201d she said aloud. \\u201cI must be\\ngetting somewhere near the centre of the earth. Let me see: that would\\nbe four thousand miles down, I think\\u2014\\u201d (for, you see, Alice had learnt\\nseveral things of this sort in her lessons in the schoolroom, and\\nthough this was not a _very_ good opportunity for showing off her\\nknowledge, as there was no one to listen to her, still it was good\\npractice to say it over) \\u201c\\u2014yes, that\\u2019s about the right distance\\u2014but\\nthen I wonder what Latitude or Longitude I\\u2019ve got to?\\u201d (Alice had no\\nidea what Latitude was, or Longitude either, but thought they were nice\\ngrand words to say.)\",\n",
      "  \"metadata\": {\n",
      "    \"source\": \"alice_in_wonderland.md\",\n",
      "    \"chapter_number\": null,\n",
      "    \"chapter_title\": null,\n",
      "    \"start_index\": -1,\n",
      "    \"chunk_number\": 1,\n",
      "    \"chunk_summary\": \"Alice falls down a rabbit\\u2011hole that turns into a deep well, where she sees cupboards, bookshelves, maps and a jar labeled \\u201cORANGE\\u202fMARMALADE\\u201d that she emptily puts away.  While descending she thinks aloud, \\u201cWell!\\u201d and muses that after such a fall she would \\u201cthink nothing of tumbling down stairs\\u201d or even \\u201cfall off the top of the house.\\u201d  As she continues, she wonders, \\u201cI wonder how many miles I\\u2019ve fallen by this time?\\u201d and speculates about reaching the centre of the earth, even though she has no real idea of latitude or longitude.\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"content\": \"Presently she began again. \\u201cI wonder if I shall fall right _through_\\nthe earth! How funny it\\u2019ll seem to come out among the people that walk\\nwith their heads downward! The Antipathies, I think\\u2014\\u201d (she was rather\\nglad there _was_ no one listening, this time, as it didn\\u2019t sound at all\\nthe right word) \\u201c\\u2014but I shall have to ask them what the name of the\\ncountry is, you know. Please, Ma\\u2019am, is this New Zealand or Australia?\\u201d\\n(and she tried to curtsey as she spoke\\u2014fancy _curtseying_ as you\\u2019re\\nfalling through the air! Do you think you could manage it?) \\u201cAnd what\\nan ignorant little girl she\\u2019ll think me for asking! No, it\\u2019ll never do\\nto ask: perhaps I shall see it written up somewhere.\\u201d\\n\\nDown, down, down. There was nothing else to do, so Alice soon began\\ntalking again. \\u201cDinah\\u2019ll miss me very much to-night, I should think!\\u201d\\n(Dinah was the cat.) \\u201cI hope they\\u2019ll remember her saucer of milk at\\ntea-time. Dinah my dear! I wish you were down here with me! There are\\nno mice in the air, I\\u2019m afraid, but you might catch a bat, and that\\u2019s\\nvery like a mouse, you know. But do cats eat bats, I wonder?\\u201d And here\\nAlice began to get rather sleepy, and went on saying to herself, in a\\ndreamy sort of way, \\u201cDo cats eat bats? Do cats eat bats?\\u201d and\\nsometimes, \\u201cDo bats eat cats?\\u201d for, you see, as she couldn\\u2019t answer\\neither question, it didn\\u2019t much matter which way she put it. She felt\\nthat she was dozing off, and had just begun to dream that she was\\nwalking hand in hand with Dinah, and saying to her very earnestly,\\n\\u201cNow, Dinah, tell me the truth: did you ever eat a bat?\\u201d when suddenly,\\nthump! thump! down she came upon a heap of sticks and dry leaves, and\\nthe fall was over.\",\n",
      "  \"metadata\": {\n",
      "    \"source\": \"alice_in_wonderland.md\",\n",
      "    \"chapter_number\": \"Chapter I\",\n",
      "    \"chapter_title\": \"Down the Rabbit-Hole\",\n",
      "    \"start_index\": 3895,\n",
      "    \"chunk_number\": 2,\n",
      "    \"chunk_summary\": \"Alice drifts \\u201cright through the earth,\\u201d marveling at the absurdity of emerging among people who \\u201cwalk with their heads downward\\u201d and jokingly asking, \\u201cPlease, Ma\\u2019am, is this New\\u202fZealand or Australia?\\u201d as she even tries to \\u201ccurtsey as you\\u2019re falling through the air!\\u201d (she notes it \\u201cdidn\\u2019t sound at all the right word\\u201d). While falling, she muses about her cat Dinah, wondering, \\u201cDo cats eat bats? Do cats eat bats?\\u201d and even flips the question, \\u201cDo bats eat cats?\\u201d before finally crashing onto a heap of sticks and dry leaves, ending the descent.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Load and chunk the book (token-aware) + batch summarization via OpenRouter (gpt-oss-20b)\n",
    "import os, json, re, requests\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- Summarization pipeline (OpenRouter: openai/gpt-oss-20b) ---\n",
    "class OpenRouterSummarizer:\n",
    "    def __init__(self, model=\"openai/gpt-oss-20b\", api_key=None):\n",
    "        self.model = model\n",
    "        self.api_key = api_key or os.getenv(\"OPENROUTER_API_KEY\")\n",
    "        assert self.api_key, \"OpenRouter API key not found. Set OPENROUTER_API_KEY in your .env.\"\n",
    "\n",
    "    # Keep the same call signature you used before\n",
    "    def __call__(self, texts, max_length=40, min_length=10, do_sample=False, batch_size=8):\n",
    "        url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        results = []\n",
    "        for t in texts:\n",
    "            prompt = (\n",
    "                \"Summarize the passage in 2-3 sentences as per the content, capture the main point of the content and make sure you're not missing out on the quotes from the content.\"\n",
    "                f\"Passage:\\n{t}\\n\\nSummary:\"\n",
    "            )\n",
    "            payload = {\n",
    "                \"model\": self.model,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": 0.2,\n",
    "            }\n",
    "            r = requests.post(url, headers=headers, json=payload, timeout=120)\n",
    "            r.raise_for_status()\n",
    "            content = r.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            results.append({\"summary_text\": content})\n",
    "        return results\n",
    "\n",
    "# Initialize summarizer (variable name unchanged)\n",
    "summarizer = OpenRouterSummarizer(model=\"openai/gpt-oss-20b\")\n",
    "\n",
    "# --- Function: parse chapters (captures both same-line and next-line titles) ---\n",
    "def parse_chapters(text):\n",
    "    \"\"\"\n",
    "    Matches:\n",
    "      Contents lines:  'CHAPTER I. Down the Rabbit-Hole'\n",
    "      Chapter headers: 'CHAPTER I.\\nDown the Rabbit-Hole'\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"CHAPTER\\s+([IVXLCDM]+)\\.\\s*(?:([^\\n]+)|\\n([^\\n]+))\")\n",
    "    chapters = []\n",
    "    for m in pattern.finditer(text):\n",
    "        title = (m.group(2) or m.group(3) or \"\").strip()\n",
    "        chapters.append({\n",
    "            \"start\": m.start(),\n",
    "            \"chapter_number\": f\"Chapter {m.group(1)}\",\n",
    "            \"chapter_title\": title\n",
    "        })\n",
    "    chapters.sort(key=lambda x: x[\"start\"])\n",
    "    return chapters\n",
    "\n",
    "# --- Function: split and summarize (token-aware, reliable start_index) ---\n",
    "def load_and_chunk_markdown(md_path, chunk_size=600, chunk_overlap=100, batch_size=10):\n",
    "    with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        full_text = f.read()\n",
    "\n",
    "    chapters = parse_chapters(full_text)\n",
    "\n",
    "    # Token-aware splitter with start indices:\n",
    "    # NOTE: pass add_start_index=True on the splitter (NOT on create_documents)\n",
    "    try:\n",
    "        splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            add_start_index=True\n",
    "        )\n",
    "    except TypeError:\n",
    "        # Fallback for older LangChain versions: construct directly\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            add_start_index=True\n",
    "        )\n",
    "\n",
    "    # create_documents returns documents with metadata['start_index']\n",
    "    doc_objs = splitter.create_documents([full_text])\n",
    "\n",
    "    # Prepare raw chunk strings for summarizer call\n",
    "    chunks = [d.page_content for d in doc_objs]\n",
    "\n",
    "    # üîπ Summarize chunks (OpenRouter; sequential for clarity)\n",
    "    summaries = summarizer(\n",
    "        chunks,\n",
    "        max_length=40,\n",
    "        min_length=10,\n",
    "        do_sample=False,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    docs = []\n",
    "    for i, (d, summary_obj) in enumerate(zip(doc_objs, summaries)):\n",
    "        start_index = d.metadata.get(\"start_index\", None)\n",
    "        chunk = d.page_content\n",
    "        summary = summary_obj[\"summary_text\"]\n",
    "\n",
    "        # Find chapter for this chunk by position (binary search style)\n",
    "        chapter_number, chapter_title = None, None\n",
    "        if start_index is not None and chapters:\n",
    "            lo, hi, idx = 0, len(chapters)-1, -1\n",
    "            while lo <= hi:\n",
    "                mid = (lo + hi) // 2\n",
    "                if chapters[mid][\"start\"] <= start_index:\n",
    "                    idx = mid\n",
    "                    lo = mid + 1\n",
    "                else:\n",
    "                    hi = mid - 1\n",
    "            if idx >= 0:\n",
    "                chapter_number = chapters[idx][\"chapter_number\"]\n",
    "                chapter_title = chapters[idx][\"chapter_title\"]\n",
    "\n",
    "        docs.append({\n",
    "            \"content\": chunk,\n",
    "            \"metadata\": {\n",
    "                \"source\": md_path,\n",
    "                \"chapter_number\": chapter_number,     # e.g., \"Chapter I\"\n",
    "                \"chapter_title\": chapter_title,       # e.g., \"Down the Rabbit-Hole\"\n",
    "                \"start_index\": start_index,\n",
    "                \"chunk_number\": i,\n",
    "                \"chunk_summary\": summary\n",
    "            }\n",
    "        })\n",
    "\n",
    "    return docs\n",
    "\n",
    "# Load and chunk with batching\n",
    "print(\"‚ö° Summarizing chunks with OpenRouter gpt-oss-20b (token-aware splitting)...\")\n",
    "docs = load_and_chunk_markdown(\"alice_in_wonderland.md\", batch_size=8)\n",
    "\n",
    "# #printing\n",
    "print(\"### Example 3 Chunks ###\")\n",
    "for d in docs[:3]:\n",
    "    print(json.dumps(d, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01228159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from_texts() takes each chunk from texts=[d[\"content\"] for d in docs].\\nFor each chunk, it calls embeddings.embed_text(text) under the hood.\\nembed_text converts the chunk into a high-dimensional vector (embedding).\\nThese vectors are then stored in Chroma along with your metadata. '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from_texts() takes each chunk from texts=[d[\"content\"] for d in docs].\n",
    "For each chunk, it calls embeddings.embed_text(text) under the hood.\n",
    "embed_text converts the chunk into a high-dimensional vector (embedding).\n",
    "These vectors are then stored in Chroma along with your metadata. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac4d832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Vector DB Info ###\n",
      "Persist dir: ./chroma_store\n",
      "Total vectors stored: 272\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Build embeddings + vectorstore (persistent Chroma; cosine)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "vectordb = Chroma.from_texts(\n",
    "    texts=[d[\"content\"] for d in docs],\n",
    "    embedding=embeddings,\n",
    "    metadatas=[d[\"metadata\"] for d in docs],\n",
    "    persist_directory=\"./chroma_store\",              \n",
    "    collection_name=\"alice\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}     \n",
    ")\n",
    "vectordb.persist()  # save to disk\n",
    "\n",
    "# #printing\n",
    "print(\"### Vector DB Info ###\")\n",
    "print(\"Persist dir:\", \"./chroma_store\")\n",
    "print(\"Total vectors stored:\", vectordb._collection.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f81f12ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Multi-Query Expansions ###\n",
      "Original: What are the contents in the book?\n",
      "Q1: Could you tell me what's inside the book?\n",
      "Q2: What topics are covered in the book?\n",
      "Q3: What is the book about?\n",
      "Q4: What does the book contain?\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Multi-query expansions (use Gemini)\n",
    "# Generate 4 alternative phrasings of the user question\n",
    "\n",
    "def expand_queries(llm, question, n=4):\n",
    "    prompt = f\"\"\"\n",
    "    Generate {n} different phrasings of the following user question:\n",
    "    \"{question}\"\n",
    "    Provide only the variations, one per line.\n",
    "    \"\"\"\n",
    "    out = llm.invoke(prompt)\n",
    "    expansions = list(set(out.content.strip().split(\"\\n\")))\n",
    "    return [q.strip(\"- \").strip() for q in expansions if q.strip()]\n",
    "\n",
    "llm_gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.3,\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "user_question = \"What are the contents in the book?\"\n",
    "expansions = expand_queries(llm_gemini, user_question)\n",
    "\n",
    "#printing\n",
    "print(\"### Multi-Query Expansions ###\")\n",
    "print(\"Original:\", user_question)\n",
    "for i, e in enumerate(expansions, 1):\n",
    "    print(f\"Q{i}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7c14e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Retrieved Candidates ###\n",
      "Query: What are the contents in the book?\n",
      "Score (cosine ANN): 0.3952\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=Chapter XII | chapter_title=Alice‚Äôs Evidence | position=134839 | chunk_number=84 | chunk_summary=The King interrogates Alice about the business, insisting it is ‚Äúimportant‚Äîunimportant‚Äîunimportant‚Äîimportant‚Äî‚Äù while Alice simply replies ‚ÄúNothing‚Äù and ‚ÄúNothing whatever,‚Äù prompting the White Rabbit to correct the King that it is ‚ÄúUn_important, your Majesty means, of course,‚Äù and the jury records either ‚Äúimportant‚Äù or ‚Äúunimportant.‚Äù  Suddenly the King cites ‚ÄúRule Forty‚Äëtwo. All persons more than a mile high to leave the court,‚Äù to which Alice protests, ‚ÄúI‚Äôm not a mile high,‚Äù the King retorts, ‚ÄúYou are,‚Äù and the Queen adds, ‚ÄúNearly two miles high,‚Äù while Alice counters, ‚ÄúWell, I shan‚Äôt go, at any rate,‚Äù and insists the rule should be ‚ÄúNumber One.‚Äù  The King, unsettled, orders the jury to ‚ÄúConsider your verdict,‚Äù the White Rabbit promises more evidence, and the Queen asks, ‚ÄúWhat‚Äôs in it?‚Äù capturing the chaotic exchange.\n",
      "---\n",
      "Query: What are the contents in the book?\n",
      "Score (cosine ANN): 0.3952\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=Chapter XII | chapter_title=Alice‚Äôs Evidence | position=133976 | chunk_number=83 | chunk_summary=The King questions Alice about the business, to which she replies ‚ÄúNothing,‚Äù and he insists, prompting the White Rabbit to interject, ‚ÄúUn_important, your Majesty means, of course,‚Äù which leads to a confusion over whether the matter is ‚Äúimportant‚Äù or ‚Äúunimportant‚Äù as the jury scribbles it down. The King then cackles ‚ÄúSilence!‚Äù and reads Rule Forty‚Äëtwo, ‚ÄúAll persons more than a mile high to leave the court,‚Äù prompting Alice to protest, ‚ÄúI‚Äôm not a mile high,‚Äù while the Queen counters, ‚ÄúNearly two miles high,‚Äù and the King, startled, closes his notebook and urges the jury to ‚ÄúConsider your verdict.‚Äù The White Rabbit, eager to add evidence, declares, ‚ÄúThis paper has just been picked up,‚Äù and the Queen asks, ‚ÄúWhat‚Äôs in it?‚Äù as the court awaits further developments.\n",
      "---\n",
      "Query: What are the contents in the book?\n",
      "Score (cosine ANN): 0.4197\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=Chapter IV | chapter_title=The Rabbit Sends in a Little Bill | position=46000 | chunk_number=28 | chunk_summary=Alice finds herself atop a large mushroom where a blue caterpillar sits smoking a hookah, and the two stare each other down in silence before the caterpillar asks, ‚ÄúWho are _you?_.‚Äù Alice, bewildered by her continual changes of size, replies that she ‚Äúcan‚Äôt explain _myself_, I‚Äôm afraid, sir, because I‚Äôm not myself, you see,‚Äù and the caterpillar simply says, ‚ÄúIt isn‚Äôt.‚Äù The exchange ends with the caterpillar dismissing any future metamorphosis as ‚ÄúNot a bit,‚Äù leaving Alice to ponder her own confusing identity.\n",
      "---\n",
      "Query: What are the contents in the book?\n",
      "Score (cosine ANN): 0.4197\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=Chapter IV | chapter_title=The Rabbit Sends in a Little Bill | position=45137 | chunk_number=27 | chunk_summary=Alice wanders in the garden, unable to find food, and spots a large blue caterpillar perched atop a mushroom, smoking a hookah. The caterpillar asks, ‚ÄúWho are _you?_,‚Äù and Alice replies, ‚ÄúI‚ÄîI hardly know, sir, just at present‚Äîat least I know who I _was_ when I got up this morning, but I think I must have been changed several times since then.‚Äù The conversation turns to identity and transformation, with the caterpillar insisting, ‚ÄúNot a bit,‚Äù when Alice wonders if it will feel ‚Äúa little queer‚Äù after becoming a butterfly.\n",
      "---\n",
      "Query: What are the contents in the book?\n",
      "Score (cosine ANN): 0.4211\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=Chapter III | chapter_title=A Caucus-Race and a Long Tale | position=26827 | chunk_number=16 | chunk_summary=‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù  It set up a loose race‚Äëcourse, let the participants run whenever they pleased, and after half an hour called out, ‚ÄúThe race is over!‚Äù  When asked who had won, the Dodo declared, ‚ÄúEverybody has won, and all must have prizes,‚Äù and directed everyone to Alice, who, after a moment of confusion, handed out a box of comfits and then a single thimble, saying, ‚ÄúWe beg your acceptance of this elegant thimble;‚Äù to which the crowd cheered.\n",
      "---\n",
      "Query: What are the contents in the book?\n",
      "Score (cosine ANN): 0.4211\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=Chapter III | chapter_title=A Caucus-Race and a Long Tale | position=26026 | chunk_number=15 | chunk_summary=‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it,‚Äù and so it set up a loose, circular race‚Äëcourse, letting the participants start and stop whenever they liked, only to shout ‚ÄúThe race is over!‚Äù after half an hour and ask ‚ÄúBut who has won?‚Äù The Dodo, after a long pause with one finger pressed upon its forehead, declared ‚ÄúEverybody has won, and all must have prizes,‚Äù and pointed to Alice as the giver, who then handed out a box of comfits and, after the Mouse insisted she too deserved a prize, a thimble she had in her pocket, which the Dodo solemnly presented with the words ‚ÄúWe beg your acceptance of this elegant thimble.‚Äù Thus the whimsical contest ended with everyone cheering, each receiving a prize, and the lesson that the best way to explain something is to show it in action.\n",
      "---\n",
      "Query: What are the contents in the book?\n",
      "Score (cosine ANN): 0.4213\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=N/A | chapter_title= | position=-1 | chunk_number=5 | chunk_summary=Alice shrinks to ten inches, remarking, ‚ÄúWhat a curious feeling!‚Äù and ‚ÄúI must be shutting up like a telescope,‚Äù and she hopes to pass through a little door into a garden. After a nervous pause, she decides to go, only to find she has forgotten the key and cannot reach it, so she sits down and cries. Scolding herself sharply, she says, ‚ÄúI advise you to leave off this minute!‚Äù and laments that there isn‚Äôt even enough of herself left to be a respectable person.\n",
      "---\n",
      "Query: Could you tell me what's inside the book?\n",
      "Score (cosine ANN): 0.4324\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=Chapter V | chapter_title=Advice from a Caterpillar | position=52558 | chunk_number=32 | chunk_summary=Alice wonders, ‚ÄúOne side of _what?_ The other side of _what?_‚Äù and the Caterpillar replies, ‚ÄúOf the mushroom,‚Äù prompting her to try to distinguish the two sides of a perfectly round mushroom by biting each half, only to be struck by a sudden blow that makes her feel her foot hit her chin. As she shrinks rapidly, she manages to swallow a piece of the left-hand bit while her chin presses against her foot, then exclaims, ‚ÄúCome, my head‚Äôs free at last!‚Äù only to discover her shoulders have vanished, leaving her with an immense neck rising like a stalk amid a sea of green leaves. The passage captures Alice‚Äôs bewildered attempts to understand the mushroom‚Äôs sides and the surreal, disorienting changes she experiences as she grows and loses parts of her body.\n",
      "---\n",
      "Query: Could you tell me what's inside the book?\n",
      "Score (cosine ANN): 0.4324\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=Chapter V | chapter_title=Advice from a Caterpillar | position=51695 | chunk_number=31 | chunk_summary=Alice wonders, ‚ÄúOne side of _what?_ The other side of _what?_,‚Äù and the Caterpillar answers, ‚ÄúOf the mushroom,‚Äù prompting her to try to distinguish the two sides of a perfectly round mushroom by biting each half. After a sudden blow that makes her feel her foot under her chin, she shrinks rapidly and continues to eat, only to find her head free and her shoulders vanished, leaving her with a long neck that seems to rise like a stalk from a sea of green leaves. She laments, ‚ÄúWhat _can_ all that green stuff be?‚Äù and ‚ÄúWhere _have_ my shoulders got to?‚Äù as she struggles to understand her new, bizarre form.\n",
      "---\n",
      "Query: What topics are covered in the book?\n",
      "Score (cosine ANN): 0.4711\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=N/A | chapter_title= | position=1 | chunk_number=0 | chunk_summary=Alice, bored while sitting beside her sister, remarks that ‚Äúwithout pictures or conversations‚Äù a book is useless and contemplates making a daisy‚Äëchain, only to be interrupted by a White Rabbit who exclaims, ‚ÄúOh dear! Oh dear! I shall be late!‚Äù and pulls a watch from its waistcoat‚Äëpocket. Intrigued, she chases the rabbit down a large rabbit‚Äëhole, and, without a second thought, falls into a deep well, beginning her fantastical adventure. The passage captures her initial curiosity and the moment she steps into the unknown, setting the stage for the whimsical journey that follows.\n",
      "---\n",
      "Query: What is the book about?\n",
      "Score (cosine ANN): 0.4273\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=Chapter IX | chapter_title=The Mock Turtle‚Äôs Story | position=109633 | chunk_number=68 | chunk_summary=Alice questions the meaning of ‚Äúmaking anything prettier,‚Äù and the Gryphon replies, ‚ÄúWell, then, if you don‚Äôt know what to uglify is, you are a simpleton,‚Äù prompting her to ask the Mock Turtle about his studies. The Mock Turtle lists odd subjects‚ÄîMystery, Seaography, Drawling, Stretching, and Fainting in Coils‚Äîadding that ‚ÄúTen hours the first day, nine the next, and so on,‚Äù while the Gryphon explains that lessons ‚Äúlessen from day to day.‚Äù Alice wonders about the eleventh day, to which the Mock Turtle answers, ‚ÄúOf course it was,‚Äù confirming the peculiar curriculum‚Äôs pattern.\n",
      "---\n",
      "Query: What is the book about?\n",
      "Score (cosine ANN): 0.4273\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=Chapter IX | chapter_title=The Mock Turtle‚Äôs Story | position=108770 | chunk_number=67 | chunk_summary=Alice asks the Gryphon and the Mock Turtle what they have learned, and they explain that their curriculum includes subjects such as ‚ÄúMystery,‚Äù ‚ÄúSeaography,‚Äù ‚ÄúDrawling,‚Äù ‚ÄúStretching,‚Äù and ‚ÄúFainting in Coils,‚Äù with the Mock Turtle noting that ‚Äúhe taught Laughing and Grief, they used to say.‚Äù The Gryphon adds that the lessons ‚Äúlessen from day to day,‚Äù with the Mock Turtle recalling that they began with ‚Äúten hours the first day,‚Äù then ‚Äúnine the next, and so on,‚Äù implying that the eleventh day was a holiday. The conversation ends with Alice curious about how they managed on the twelfth day, highlighting the whimsical and nonsensical nature of their education.\n",
      "---\n",
      "Query: What is the book about?\n",
      "Score (cosine ANN): 0.4406\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=N/A | chapter_title= | position=-1 | chunk_number=15 | chunk_summary=The Duck asks, ‚ÄúFound _what_?‚Äù and the Mouse replies, ‚ÄúFound _it_,‚Äù prompting the Duck to wonder, ‚Äúwhat did the archbishop find?‚Äù The discussion then shifts to a meeting where the Dodo, after a brief interjection from the Eaglet, proposes a ‚ÄúCaucus‚Äërace‚Äù as a remedy, and Alice asks, ‚ÄúWhat _is_ a Caucus‚Äërace?‚Äù before the Dodo replies, ‚ÄúWhy, the best way to explain it is to do it.‚Äù\n",
      "---\n",
      "Query: What is the book about?\n",
      "Score (cosine ANN): 0.4406\n",
      "Meta: source=alice_in_wonderland.md | chapter_number=N/A | chapter_title= | position=-1 | chunk_number=14 | chunk_summary=In the dialogue, the Duck asks the Mouse ‚ÄúFound _what_?‚Äù while the Mouse replies, ‚ÄúFound _it_,‚Äù and the Duck counters, ‚ÄúI know what ‚Äòit‚Äô means well enough, when _I_ find a thing.‚Äù The conversation then shifts to a historical anecdote about ‚ÄúEdgar Atheling‚Äù and ‚ÄúWilliam‚Äù as the Mouse narrates, while Alice laments, ‚ÄúAs wet as ever,‚Äù and the Dodo proposes, ‚Äúthe best thing to get us dry would be a Caucus‚Äërace.‚Äù The Eaglet protests, ‚ÄúSpeak English!‚Äù and the Dodo, offended, insists, ‚ÄúWhy, the best way to explain it is to do it,‚Äù hinting at a playful demonstration of the mysterious Caucus‚Äërace.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Retrieve chunks (cosine similarity) for original + expansions\n",
    "\n",
    "def retrieve_candidates(vectordb, queries, per_query_k=5):\n",
    "    results = []\n",
    "    seen = set()\n",
    "    for q in queries:\n",
    "        hits = vectordb.similarity_search_with_score(q, k=per_query_k)\n",
    "        for doc, score in hits:\n",
    "            key = (doc.metadata[\"start_index\"], doc.metadata[\"chunk_number\"])\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                results.append((doc, score, q))\n",
    "    return results\n",
    "\n",
    "queries = [user_question] + expansions\n",
    "candidates = retrieve_candidates(vectordb, queries, per_query_k=10)\n",
    "\n",
    "# #printing\n",
    "# #printing\n",
    "print(\"### Retrieved Candidates ###\")\n",
    "\n",
    "def _get(m, k, default=\"\"):\n",
    "    return m.get(k, default)\n",
    "\n",
    "for idx, (doc, score, q) in enumerate(candidates[:20], 1):\n",
    "    m = doc.metadata or {}\n",
    "    meta_line = (\n",
    "        f\"source={_get(m,'source')} | \"\n",
    "        f\"chapter_number={_get(m,'chapter_number','N/A')} | \"\n",
    "        f\"chapter_title={_get(m,'chapter_title','')} | \"\n",
    "        f\"position={_get(m,'start_index','-')} | \"\n",
    "        f\"chunk_number={_get(m,'chunk_number','-')} | \"\n",
    "        f\"chunk_summary={_get(m,'chunk_summary','')}\"\n",
    "    )\n",
    "    print(f\"Query: {q}\")\n",
    "    print(f\"Score (cosine ANN): {score:.4f}\")\n",
    "    print(\"Meta:\", meta_line)\n",
    "    print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "697a11ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Top Reranked Docs ###\n",
      "RERANK=-2.0566 | Unknown Unknown | Alice, bored while sitting beside her sister, remarks that ‚Äúwithout pictures or conversations‚Äù a boo...\n",
      "RERANK=-8.3906 | Unknown Unknown | The Duck asks, ‚ÄúFound _what_?‚Äù and the Mouse replies, ‚ÄúFound _it_,‚Äù prompting the Duck to wonder, ‚Äúw...\n",
      "RERANK=-8.5391 | Chapter XII Alice‚Äôs Evidence | The King interrogates Alice about the business, insisting it is ‚Äúimportant‚Äîunimportant‚Äîunimportant‚Äîi...\n",
      "RERANK=-8.5391 | Chapter XII Alice‚Äôs Evidence | The King questions Alice about the business, to which she replies ‚ÄúNothing,‚Äù and he insists, prompti...\n",
      "RERANK=-8.8906 | Chapter V Advice from a Caterpillar | Alice wonders, ‚ÄúOne side of _what?_ The other side of _what?_‚Äù and the Caterpillar replies, ‚ÄúOf the ...\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: Rerank candidates with cross-encoder (dedupe; take top 5)\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "reranker = FlagReranker(\"BAAI/bge-reranker-base\", use_fp16=True)\n",
    "\n",
    "def rerank_candidates(question, candidates, top_n=10):\n",
    "    pairs = [[question, doc.page_content] for doc, _, _ in candidates]\n",
    "    scores = reranker.compute_score(pairs)\n",
    "    reranked = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Deduplicate by start_index\n",
    "    seen = set()\n",
    "    top_docs = []\n",
    "    for (doc, score, q), rerank_score in reranked:\n",
    "        if doc.metadata[\"start_index\"] not in seen:\n",
    "            seen.add(doc.metadata[\"start_index\"])\n",
    "            top_docs.append((doc, rerank_score))\n",
    "        if len(top_docs) == top_n:\n",
    "            break\n",
    "    return top_docs\n",
    "\n",
    "top_docs = rerank_candidates(user_question, candidates, top_n=5)\n",
    "\n",
    "# #printing\n",
    "# #printing\n",
    "print(\"### Top Reranked Docs ###\")\n",
    "for d, s in top_docs:\n",
    "    m = d.metadata or {}\n",
    "    chapter_number = m.get('chapter_number', 'Unknown')\n",
    "    chapter_title  = m.get('chapter_title', 'Unknown')\n",
    "    chunk_summary  = (m.get('chunk_summary') or '')[:100]\n",
    "    print(f\"RERANK={s:.4f} | {chapter_number} {chapter_title} | {chunk_summary}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebad5599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### FINAL ANSWER ###\n",
      "The book contains twelve chapters, each detailing a different adventure. These chapters include \"Down the Rabbit-Hole,\" \"The Pool of Tears,\" \"A Caucus-Race and a Long Tale,\" \"The Rabbit Sends in a Little Bill,\" \"Advice from a Caterpillar,\" \"Pig and Pepper,\" \"A Mad Tea-Party,\" \"The Queen‚Äôs Croquet-Ground,\" \"The Mock Turtle‚Äôs Story,\" \"The Lobster Quadrille,\" \"Who Stole the Tarts?,\" and \"Alice‚Äôs Evidence.\" These titles provide a clear outline of the narrative journey within the book.\n",
      "### Context Headers Preview ###\n",
      "[Source: alice_in_wonderland.md | Chapter Unknown Unknown | Position=1 | Chunk 0]\n",
      "[Source: alice_in_wonderland.md | Chapter Unknown Unknown | Position=-1 | Chunk 15]\n",
      "[Source: alice_in_wonderland.md | Chapter Chapter XII Alice‚Äôs Evidence | Position=134839 | Chunk 84]\n",
      "[Source: alice_in_wonderland.md | Chapter Chapter XII Alice‚Äôs Evidence | Position=133976 | Chunk 83]\n",
      "[Source: alice_in_wonderland.md | Chapter Chapter V Advice from a Caterpillar | Position=52558 | Chunk 32]\n"
     ]
    }
   ],
   "source": [
    "# STEP 9: Build context and answer with Gemini (final result)\n",
    "\n",
    "def build_context(docs):\n",
    "    parts = []\n",
    "    for d, _ in docs:\n",
    "        m = getattr(d, \"metadata\", {}) or {}\n",
    "        source         = m.get(\"source\", \"unknown\")\n",
    "        chapter_number = m.get(\"chapter_number\", \"Unknown\")\n",
    "        chapter_title  = m.get(\"chapter_title\", \"Unknown\")\n",
    "        start_index    = m.get(\"start_index\", \"?\")\n",
    "        chunk_number   = m.get(\"chunk_number\", \"?\")\n",
    "        header = f\"[Source: {source} | Chapter {chapter_number} {chapter_title} | Position={start_index} | Chunk {chunk_number}]\"\n",
    "        parts.append(header + \"\\n\" + d.page_content)\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "context = build_context(top_docs)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant. \n",
    "Answer the user question using ONLY the provided context.\n",
    "Read the chunk summary carefully and if it matches with the question then check the chunk content and answer the question.\n",
    "Expand the answer into at least 2‚Äì3 sentences and don't use quotes from the content unless the question is asking for the quotes.\n",
    "\n",
    "\n",
    "Question: {question}\n",
    "Context:\n",
    "{context}\n",
    "\"\"\")\n",
    "\n",
    "answer = llm_gemini.invoke(prompt.format(question=user_question, context=context))\n",
    "\n",
    "# #printing\n",
    "print(\"### FINAL ANSWER ###\")\n",
    "print(answer.content)\n",
    "\n",
    "# #printing\n",
    "\n",
    "print(\"### Context Headers Preview ###\")\n",
    "for d, _ in top_docs:\n",
    "    m = d.metadata or {}\n",
    "    print(f\"[Source: {m.get('source','unknown')} | Chapter {m.get('chapter_number','Unknown')} {m.get('chapter_title','Unknown')} | Position={m.get('start_index','?')} | Chunk {m.get('chunk_number','?')}]\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
