{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407e2cf0",
   "metadata": {},
   "source": [
    "Here's the diagram for the process : [rag_image](mermaid_rag.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9911ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Install dependencies\n",
    "\n",
    "%pip install langchain langchain-community langchain-huggingface langchain-google-genai --quiet\n",
    "%pip install chromadb sentence-transformers FlagEmbedding huggingface_hub --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7225c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Imports\n",
    "import os, re, json\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain components\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Reranker\n",
    "from FlagEmbedding import FlagReranker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8600151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Authentication (Hugging Face + Gemini key)\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Hugging Face login\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(HF_TOKEN)\n",
    "\n",
    "# Gemini API key\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "assert GOOGLE_API_KEY, \"Gemini API Key not found!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6e00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Summarizing chunks with batching (this may take ~2â€“3 minutes on CPU)...\n",
      "### Example 3 Chunks ###\n",
      "{\n",
      "  \"content\": \"The Project Gutenberg eBook of Alice's Adventures in Wonderland\\n\\nThis ebook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this ebook or online\\nat www.gutenberg.org. If you are not located in the United States,\\nyou will have to check the laws of the country where you are located\\nbefore using this eBook.\\n\\nTitle: Alice's Adventures in Wonderland\\n\\nAuthor: Lewis Carroll\\n\\nRelease date: June 27, 2008 [eBook #11]\\nMost recently updated: March 30, 2021\\n\\nLanguage: English\\n\\nCredits: Arthur DiBianca and David Widger\\n\\n**_ START OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND _**\",\n",
      "  \"metadata\": {\n",
      "    \"source\": \"alice_in_wonderland.md\",\n",
      "    \"chapter_number\": null,\n",
      "    \"chapter_title\": null,\n",
      "    \"start_index\": 0,\n",
      "    \"chunk_number\": 0,\n",
      "    \"chunk_summary\": \" The Project Gutenberg eBook of Alice's Adventures in Wonderland is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions .\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"content\": \"Language: English\\n\\nCredits: Arthur DiBianca and David Widger\\n\\n**_ START OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND _**\\n\\nAlice\\u2019s Adventures in Wonderland\\n\\nby Lewis Carroll\\n\\nTHE MILLENNIUM FULCRUM EDITION 3.0\\n\\nContents\\n\\nCHAPTER I. Down the Rabbit-Hole\\nCHAPTER II. The Pool of Tears\\nCHAPTER III. A Caucus-Race and a Long Tale\\nCHAPTER IV. The Rabbit Sends in a Little Bill\\nCHAPTER V. Advice from a Caterpillar\\nCHAPTER VI. Pig and Pepper\\nCHAPTER VII. A Mad Tea-Party\\nCHAPTER VIII. The Queen\\u2019s Croquet-Ground\\nCHAPTER IX. The Mock Turtle\\u2019s Story\\nCHAPTER X. The Lobster Quadrille\\nCHAPTER XI. Who Stole the Tarts?\\nCHAPTER XII. Alice\\u2019s Evidence\\n\\nCHAPTER I.\\nDown the Rabbit-Hole\",\n",
      "  \"metadata\": {\n",
      "    \"source\": \"alice_in_wonderland.md\",\n",
      "    \"chapter_number\": null,\n",
      "    \"chapter_title\": null,\n",
      "    \"start_index\": 652,\n",
      "    \"chunk_number\": 1,\n",
      "    \"chunk_summary\": \" The MILLENNIUM FULCRUM EDITION 3.0 is the first edition of Alice\\u2019s Adventures in Wonderland by Lewis Carroll . The book includes chapters: Down the\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"content\": \"CHAPTER I.\\nDown the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into\\nthe book her sister was reading, but it had no pictures or\\nconversations in it, \\u201cand what is the use of a book,\\u201d thought Alice\\n\\u201cwithout pictures or conversations?\\u201d\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure of\\nmaking a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\",\n",
      "  \"metadata\": {\n",
      "    \"source\": \"alice_in_wonderland.md\",\n",
      "    \"chapter_number\": 13,\n",
      "    \"chapter_title\": \"CHAPTER I.\",\n",
      "    \"start_index\": 1309,\n",
      "    \"chunk_number\": 2,\n",
      "    \"chunk_summary\": \" Alice was beginning to get tired of sitting by her sister on the bank . She was considering whether the pleasure of making a daisy-chain would be worth the trouble of getting up and\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Load and chunk the book (with batching for summarization)\n",
    "from transformers import pipeline\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "\n",
    "# Summarization pipeline (DistilBART CNN)\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "# Function: parse chapters\n",
    "def parse_chapters(text):\n",
    "    headers = list(re.finditer(r\"CHAPTER\\s+([IVXLCDM]+)(.*)\", text))\n",
    "    return [(h.start(), h.group(0)) for h in headers]\n",
    "\n",
    "# Function: split and summarize (with batching)\n",
    "def load_and_chunk_markdown(md_path, chunk_size=800, chunk_overlap=200, batch_size=8):\n",
    "    with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        full_text = f.read()\n",
    "    \n",
    "    chapters = parse_chapters(full_text)\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    chunks = splitter.split_text(full_text)\n",
    "    docs = []\n",
    "\n",
    "    # ðŸ”¹ Summarize chunks in batches\n",
    "    summaries = summarizer(\n",
    "        chunks,\n",
    "        max_length=40,\n",
    "        min_length=10,\n",
    "        do_sample=False,\n",
    "        batch_size=batch_size   # batching here\n",
    "    )\n",
    "\n",
    "    for i, (chunk, summary_obj) in enumerate(zip(chunks, summaries)):\n",
    "        summary = summary_obj[\"summary_text\"]\n",
    "\n",
    "        # Find chapter for this chunk\n",
    "        start_index = full_text.find(chunk)\n",
    "        chapter_num, chapter_title = None, None\n",
    "        for pos, header in reversed(chapters):\n",
    "            if pos <= start_index:\n",
    "                chapter_num = len([c for c in chapters if c[0] <= pos])\n",
    "                chapter_title = header\n",
    "                break\n",
    "\n",
    "        docs.append({\n",
    "            \"content\": chunk,\n",
    "            \"metadata\": {\n",
    "                \"source\": md_path,\n",
    "                \"chapter_number\": chapter_num,\n",
    "                \"chapter_title\": chapter_title,\n",
    "                \"start_index\": start_index,\n",
    "                \"chunk_number\": i,\n",
    "                \"chunk_summary\": summary\n",
    "            }\n",
    "        })\n",
    "    return docs\n",
    "\n",
    "# Load and chunk with batching\n",
    "print(\"âš¡ Summarizing chunks with batching (this may take ~2â€“3 minutes on CPU)...\")\n",
    "docs = load_and_chunk_markdown(\"alice_in_wonderland.md\", batch_size=8)\n",
    "\n",
    "# printing\n",
    "print(\"### Example 3 Chunks ###\")\n",
    "for d in docs[:3]:\n",
    "    print(json.dumps(d, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01228159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from_texts() takes each chunk from texts=[d[\"content\"] for d in docs].\n",
    "For each chunk, it calls embeddings.embed_text(text) under the hood.\n",
    "embed_text converts the chunk into a high-dimensional vector (embedding).\n",
    "These vectors are then stored in Chroma along with your metadata. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac4d832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Vector DB Info ###\n",
      "Total vectors stored: 251\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Build embeddings + vectorstore (in memory Chroma)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# Build vectorstore\n",
    "vectordb = Chroma.from_texts(\n",
    "    texts=[d[\"content\"] for d in docs],\n",
    "    embedding=embeddings,\n",
    "    metadatas=[d[\"metadata\"] for d in docs],\n",
    "    collection_name=\"alice\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "#printing\n",
    "print(\"### Vector DB Info ###\")\n",
    "print(\"Total vectors stored:\", vectordb._collection.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f81f12ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Multi-Query Expansions ###\n",
      "Original: Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\n",
      "Q1: 3. Detail Alice's impetus for going after the White Rabbit, and outline the initial occurrences directly after her fall into its burrow.\n",
      "Q2: 2. Could you explain Alice's reasons for chasing the White Rabbit, and then describe what transpired the moment she plunged down the hole?\n",
      "Q3: 4. What prompted Alice to follow the White Rabbit, and what happened right after she dropped into the subterranean passage?\n",
      "Q4: 1. What was Alice's motivation for pursuing the White Rabbit, and what events immediately followed her descent into the rabbit hole?\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Multi-query expansions (use Gemini)\n",
    "# Generate 4 alternative phrasings of the user question\n",
    "\n",
    "def expand_queries(llm, question, n=4):\n",
    "    prompt = f\"\"\"\n",
    "    Generate {n} different phrasings of the following user question:\n",
    "    \"{question}\"\n",
    "    Provide only the variations, one per line.\n",
    "    \"\"\"\n",
    "    out = llm.invoke(prompt)\n",
    "    expansions = list(set(out.content.strip().split(\"\\n\")))\n",
    "    return [q.strip(\"- \").strip() for q in expansions if q.strip()]\n",
    "\n",
    "llm_gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.3,\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "user_question = \"Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\"\n",
    "expansions = expand_queries(llm_gemini, user_question)\n",
    "\n",
    "#printing\n",
    "print(\"### Multi-Query Expansions ###\")\n",
    "print(\"Original:\", user_question)\n",
    "for i, e in enumerate(expansions, 1):\n",
    "    print(f\"Q{i}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d978661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Retrieved Candidates ###\n",
      "Query: Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\n",
      "Score: 0.2055\n",
      "Meta: {'start_index': 2678, 'chapter_number': 13, 'chunk_summary': ' The rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down . In another moment down went Alice after it, never once considering how she was to get', 'source': 'alice_in_wonderland.md', 'chunk_number': 4, 'chapter_title': 'CHAPTER I.'}\n",
      "---\n",
      "Query: Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\n",
      "Score: 0.2926\n",
      "Meta: {'chapter_title': 'CHAPTER I.', 'chunk_number': 11, 'source': 'alice_in_wonderland.md', 'start_index': 6364, 'chunk_summary': ' Alice was not a bit hurt, and she jumped up on to her feet in a moment . Before her was another long passage, and the White Rabbit was still in sight, hurrying', 'chapter_number': 13}\n",
      "---\n",
      "Query: Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\n",
      "Score: 0.2928\n",
      "Meta: {'chapter_title': 'CHAPTER I.', 'chunk_summary': ' Alice was beginning to get tired of sitting by her sister on the bank . She was considering whether the pleasure of making a daisy-chain would be worth the trouble of getting up and', 'start_index': 1309, 'chapter_number': 13, 'chunk_number': 2, 'source': 'alice_in_wonderland.md'}\n",
      "---\n",
      "Query: Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\n",
      "Score: 0.3038\n",
      "Meta: {'chapter_title': 'CHAPTER I.', 'chunk_number': 3, 'source': 'alice_in_wonderland.md', 'chapter_number': 13, 'start_index': 1937, 'chunk_summary': ' Alice had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it .'}\n",
      "---\n",
      "Query: Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\n",
      "Score: 0.3059\n",
      "Meta: {'chapter_number': 14, 'chunk_summary': ' Alice felt so desperate that she was ready to ask help of any one; so, when the Rabbit came near her, she began, in a low, timid voice, â€œIf', 'start_index': 14431, 'chapter_title': 'CHAPTER II.', 'source': 'alice_in_wonderland.md', 'chunk_number': 25}\n",
      "---\n",
      "Query: 3. Detail Alice's impetus for going after the White Rabbit, and outline the initial occurrences directly after her fall into its burrow.\n",
      "Score: 0.3034\n",
      "Meta: {'chunk_summary': ' It was the White Rabbit, trotting slowly back again, as if it had lost something . Alice guessed in a moment that it was looking for the fan and the pair of white', 'chapter_title': 'CHAPTER IV.', 'chunk_number': 57, 'chapter_number': 16, 'start_index': 32848, 'source': 'alice_in_wonderland.md'}\n",
      "---\n",
      "Query: 3. Detail Alice's impetus for going after the White Rabbit, and outline the initial occurrences directly after her fall into its burrow.\n",
      "Score: 0.3136\n",
      "Meta: {'chapter_title': 'CHAPTER XII.', 'chunk_summary': ' There was a general clapping of hands at this: it was the first really-clever thing the King had said that day . The White Rabbit put on his spectacles to read', 'start_index': 137619, 'source': 'alice_in_wonderland.md', 'chunk_number': 239, 'chapter_number': 24}\n",
      "---\n",
      "Query: 3. Detail Alice's impetus for going after the White Rabbit, and outline the initial occurrences directly after her fall into its burrow.\n",
      "Score: 0.3234\n",
      "Meta: {'chapter_number': 20, 'chunk_summary': ' First came ten soldiers carrying clubs; these were shaped like the three gardeners, oblong and flat, with their hands and feet at the purposefullycorners . Next came the ten court', 'source': 'alice_in_wonderland.md', 'start_index': 86935, 'chunk_number': 152, 'chapter_title': 'CHAPTER VIII.'}\n",
      "---\n",
      "Query: 2. Could you explain Alice's reasons for chasing the White Rabbit, and then describe what transpired the moment she plunged down the hole?\n",
      "Score: 0.2755\n",
      "Meta: {'chunk_number': 207, 'source': 'alice_in_wonderland.md', 'chapter_title': 'CHAPTER X.', 'chapter_number': 22, 'start_index': 117872, 'chunk_summary': ' The Gryphon and Mock Turtle asked Alice to explain her adventures to them . She was a little nervous about it just at first, but she gained courage as she told them her adventures'}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Retrieve chunks (cosine similarity) for original + expansions\n",
    "\n",
    "def retrieve_candidates(vectordb, queries, per_query_k=5):\n",
    "    results = []\n",
    "    seen = set()\n",
    "    for q in queries:\n",
    "        hits = vectordb.similarity_search_with_score(q, k=per_query_k)\n",
    "        for doc, score in hits:\n",
    "            key = (doc.metadata[\"start_index\"], doc.metadata[\"chunk_number\"])\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                results.append((doc, score, q))\n",
    "    return results\n",
    "\n",
    "queries = [user_question] + expansions\n",
    "candidates = retrieve_candidates(vectordb, queries, per_query_k=5)\n",
    "\n",
    "#printing\n",
    "print(\"### Retrieved Candidates ###\")\n",
    "for doc, score, q in candidates[:10]:\n",
    "    meta = doc.metadata\n",
    "    print(f\"Query: {q}\")\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(f\"Meta: {meta}\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8e87baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Top Reranked Docs ###\n",
      "RERANK=3.5273 | CHAPTER I. |  The rabbit-hole went straight on like a tunnel for some way, and then dipped su...\n",
      "RERANK=2.4629 | CHAPTER I. |  Alice was beginning to get tired of sitting by her sister on the bank . She was...\n",
      "RERANK=2.1152 | CHAPTER I. |  Alice had never before seen a rabbit with either a waistcoat-pocket, or a watch...\n",
      "RERANK=1.7168 | CHAPTER II. |  Alice felt so desperate that she was ready to ask help of any one; so, when the...\n",
      "RERANK=-0.2273 | CHAPTER I. |  Alice was not a bit hurt, and she jumped up on to her feet in a moment . Before...\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: Rerank candidates with cross-encoder\n",
    "reranker = FlagReranker(\"BAAI/bge-reranker-base\", use_fp16=True)\n",
    "\n",
    "def rerank_candidates(question, candidates, top_n=5):\n",
    "    pairs = [[question, doc.page_content] for doc, _, _ in candidates]\n",
    "    scores = reranker.compute_score(pairs)\n",
    "    reranked = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Deduplicate by start_index\n",
    "    seen = set()\n",
    "    top_docs = []\n",
    "    for (doc, score, q), rerank_score in reranked:\n",
    "        if doc.metadata[\"start_index\"] not in seen:\n",
    "            seen.add(doc.metadata[\"start_index\"])\n",
    "            top_docs.append((doc, rerank_score))\n",
    "        if len(top_docs) == top_n:\n",
    "            break\n",
    "    return top_docs\n",
    "\n",
    "top_docs = rerank_candidates(user_question, candidates, top_n=5)\n",
    "\n",
    "#printing\n",
    "print(\"### Top Reranked Docs ###\")\n",
    "for d, s in top_docs:\n",
    "    print(f\"RERANK={s:.4f} | {d.metadata['chapter_title']} | {d.metadata['chunk_summary'][:80]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "509cf8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### FINAL ANSWER ###\n",
      "Alice followed the White Rabbit primarily out of curiosity. She was astonished when she saw the Rabbit take a watch out of its waistcoat-pocket and then hurry away, as she had never before seen a rabbit with such human-like characteristics. Immediately after falling down the rabbit hole, Alice found herself falling down a very deep well, and upon landing, she quickly got to her feet and saw another long passage with the White Rabbit still in sight, hurrying down it.\n",
      "\n",
      "Source: alice_in_wonderland.md | Chapter 13 CHAPTER I. | Position=1937 | Chunk 3, alice_in_wonderland.md | Chapter 13 CHAPTER I. | Position=2678 | Chunk 4, alice_in_wonderland.md | Chapter 13 CHAPTER I. | Position=6364 | Chunk 11\n"
     ]
    }
   ],
   "source": [
    "# STEP 9: Build context and answer with Gemini\n",
    "\n",
    "def build_context(docs):\n",
    "    parts = []\n",
    "    for d, _ in docs:\n",
    "        m = d.metadata\n",
    "        header = f\"[Source: {m['source']} | Chapter {m['chapter_number']} {m['chapter_title']} | Position={m['start_index']} | Chunk {m['chunk_number']}]\"\n",
    "        parts.append(header + \"\\n\" + d.page_content)\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "context = build_context(top_docs)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant. \n",
    "Answer the user question using ONLY the provided context. Read the chunk summary carefully and if it matches with the question then check the chunk content and answer the question. Exapnd the answer into atleast 2-3 sentences.\n",
    "Cite the source and chunk content at the end.                     \n",
    "\n",
    "Question: {question}\n",
    "Context:\n",
    "{context}\n",
    "\"\"\")\n",
    "\n",
    "answer = llm_gemini.invoke(prompt.format(question=user_question, context=context))\n",
    "\n",
    "#printing\n",
    "print(\"### FINAL ANSWER ###\")\n",
    "print(answer.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
